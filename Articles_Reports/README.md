# News-like Introduction of this project

## UC Berkeley Students Reinvent the Green Screen Technique 

A Hollywood movie can take 6 months to post-produce/edit. Moreover, the most recent Avengers movie Avengers: Infinity War had a budget of $320 million with 25% of that going to post-production/editing costs. Time and cost problems are surmountable for Hollywood movies but can be deal-breakers for would-be filmmakers.

Nevertheless, the DeepMasque team in Berkeley, California has created a state-of-the-art algorithm that reinvents the first few steps of the green screen technique: portrait segmentation. The algorithm captures a portraitsâ€™ facial features and feed these information along with an image into a 20-layer neural network, before refining the output with two algorithms called KNN-matting and ResNet. They also created a website where users can upload a portrait and receive a trimap, alpha matte, and a new image of themselves on a different background. Rather than slaving away on Photoshop, users can use our product in about 5 minutes. Their algorithm achieves the same accuracy as the state of the arts, but with a better UI and a lower hardware demand. DeepMasque will create the leading platform to transform the virtual reality world, Hollywood, and computer vision in the future. 
